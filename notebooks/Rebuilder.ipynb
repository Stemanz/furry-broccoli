{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec24bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "77215c3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "model1 = keras.models.load_model(\"model_56px_neuralnet_128_64_64_128_kernel3x3\")\n",
    "model2 = keras.models.load_model(\"model_128px_neuralnet_128_64_64_128_kernel3x3\")\n",
    "model3 = keras.models.load_model(\"model_dset2_56px_neuralnet_vanilla\")\n",
    "model4 = keras.models.load_model(\"model_ds2_56px_neuralnet_128_64_64_128_kernel3x3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "becoming-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoiser():\n",
    "    \"\"\" Works on PIL <Image> objects.\n",
    "    Denoiser.denoise() returns a denoised image, based on the model and\n",
    "    input parameters.\n",
    "    \n",
    "    params\n",
    "    ======\n",
    "    \n",
    "    image: an open PIL Image object\n",
    "    model: a keras trained model object\n",
    "    \n",
    "    tile_size: <int> lenght, in pixel, of the square being denoised\n",
    "        by the model. Higher values use higher amounts of RAM.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image, model, tile_size=256, debug=False, verbose=True):\n",
    "        self.image = image\n",
    "        self.model = model\n",
    "        self.tile_size = tile_size\n",
    "        self.debug = debug\n",
    "        self.verbose = verbose\n",
    "        \n",
    "\n",
    "    def _deb(self, *args, **kwargs):\n",
    "        if self.debug:\n",
    "            print(*args,**kwargs)\n",
    "\n",
    "            \n",
    "    def _say(self, *args, **kwargs):\n",
    "        if self.verbose:\n",
    "            print(*args, **kwargs)\n",
    "\n",
    "    # from Dataset class\n",
    "    def _crop_in_tiles(self, image, tile_size=56, shift=0, asarray=True):\n",
    "\n",
    "        \"\"\"\n",
    "        This generator function crops an image in several tiles\n",
    "        tile_size × tile_size squares, yielding a tile\n",
    "        every iteration.\n",
    "\n",
    "        If the input image is not a perfect multiple of\n",
    "        a(tile_size) × b(tile_size), non-square tiles are NOT\n",
    "        YIELDED.\n",
    "\n",
    "        params\n",
    "        ======\n",
    "\n",
    "        image: a Pillow open image\n",
    "        tile_size: <int> pixels; size of the tile side\n",
    "        shift: <int>: the offset from 0,0 in pixels\n",
    "        \n",
    "        yields\n",
    "        ======\n",
    "        \n",
    "        A tile_size × tile_size np.array taken form the input image,\n",
    "        but converted to float32 type and with values normalized from\n",
    "        0 to 1\n",
    "        \"\"\"\n",
    "\n",
    "        assert isinstance(tile_size, int)\n",
    "        assert isinstance(shift, int)\n",
    "        \n",
    "        self._deb(f\"debug: {tile_size} tile_size in _crop_in_tiles\")\n",
    "\n",
    "        width, height = image.size\n",
    "\n",
    "        #calculate coordinates of every tile\n",
    "        for x in range (0 + shift, width, tile_size):\n",
    "            if width - x < tile_size:\n",
    "                continue\n",
    "\n",
    "            for y in range (0 + shift, height, tile_size):\n",
    "                if height - y < tile_size:\n",
    "                    continue\n",
    "\n",
    "                # tile coord ===\n",
    "                tile_coord = (\n",
    "                    x, y, # upper left coords\n",
    "                    x + tile_size, y + tile_size # lower right coords\n",
    "                )\n",
    "\n",
    "                tile = image.crop(tile_coord)\n",
    "\n",
    "                if not asarray:\n",
    "                    yield tile #yielding tile as image\n",
    "                else:\n",
    "                    yield np.array(tile).astype(\"float32\") / 255\n",
    "        \n",
    "        \n",
    "    def _predict_tiles_from_image(self, image, model, tile_size=56):\n",
    "        \"\"\" This gives back the denoised <tiles>, according to the loaded <model>\n",
    "        The model operates on multiple tiles at once. All tiles are shaped into a form\n",
    "        that the model was trained for, then all put into a np.array container.\n",
    "        This is the way the models expects the tiles for the prediction.\n",
    "\n",
    "        NOTE: This function relies on crop_in_tiles() function.\n",
    "\n",
    "        params\n",
    "        ======\n",
    "\n",
    "        image: a pillow Image object\n",
    "        model: a keras trained model\n",
    "        \n",
    "        tile_size: <int> pixels. The model will operate and predict on a square with\n",
    "            <tile_size> side. Higher values allocate higher amounts of RAM.\n",
    "            \n",
    "        returns\n",
    "        ======\n",
    "        \n",
    "        A np.array containing all denoised (predicted) tiles\n",
    "        \"\"\"\n",
    "        \n",
    "        # all tiles need to be put into a list and reshaped to a form\n",
    "        # the model is confortable with (x,x) to (x,x,1)\n",
    "        \n",
    "        self._deb(f\"debug: {tile_size} tile_size in _predict_tiles_from_image\")\n",
    "        \n",
    "        to_predict = [\n",
    "            x.reshape(tile_size, tile_size, 1) for x in self._crop_in_tiles(image, tile_size)\n",
    "        ]\n",
    "\n",
    "        # the model expects an array of tiles, not a list of tiles\n",
    "        to_predict = np.array(to_predict)\n",
    "\n",
    "        return model.predict(to_predict)\n",
    "\n",
    "    \n",
    "    def _image_rebuilder(self, image, model, tile_size=56):\n",
    "        \"\"\" Takes as input a monochromatic (single-channel) image,\n",
    "        returns a denoised monochromatic image.\n",
    "        \n",
    "        params\n",
    "        ======\n",
    "        \n",
    "        image: a PIL monochromatic image. ONLY ONE channel is supported\n",
    "        model: a trained keras model to denoise the input image\n",
    "        \n",
    "        tile_size: <int> pixels of a square side to process at once.\n",
    "            This is not related to the tile_size the model has been built\n",
    "            with, but dictates how big is the square the model is fed with\n",
    "            for denoising. The bigger this parameter, the more RAM is needed\n",
    "            to perform the denoising.\n",
    "            This cannot be higher than the image phisical size.\n",
    "            \n",
    "        returns\n",
    "        =======\n",
    "        A monochromatic, denoised PIL.Image object\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        # I was initially wondering to manage the channel splitting here,\n",
    "        # but as the model is currently working on monochromatic images,\n",
    "        # and will eventually manage the three channels with three different\n",
    "        # models (again, with one channel per image), this stub of implementation\n",
    "        # is not necessary anymore.\n",
    "        # TODO: clear the clutter\n",
    "        channels = [image]\n",
    "\n",
    "        width, height = channels[0].size #all three channels have the same size\n",
    "        self._say(f\"width: {width}; height: {height}\")\n",
    "\n",
    "        # TODO\n",
    "        # for now, we support only exact multiples of tile_size\n",
    "        tile_width = int(width / tile_size)\n",
    "        tile_height = int(height / tile_size)\n",
    "\n",
    "        self._say(f\"Image multiple of {tile_width}×{tile_height} integer tiles.\")\n",
    "\n",
    "        for i, channel in enumerate(channels):\n",
    "            \n",
    "            # next line useless if we just process one channel\n",
    "            #self._say(f\"Processing channel {i + 1} of {len(channels)}\")\n",
    "            self._deb(f\"debug: {tile_size} tile_size in _image_rebuilder\")\n",
    "            \n",
    "            pred_tiles = [self._predict_tiles_from_image(channel, model, tile_size=tile_size)]\n",
    "\n",
    "            self._deb(f\"Predicted tiles length: {len(pred_tiles[0])}\")\n",
    "\n",
    "            # now we need to rebuild a numpy array based on the tile_width*tile_height original geometry        \n",
    "            gen = (x for x in pred_tiles[0])\n",
    "\n",
    "            # the final assembly is very fast ===\n",
    "            returnimage = []\n",
    "\n",
    "            #for i in range(tile_height):\n",
    "            #    row_tiles = next(gen)\n",
    "            #    for j in range(tile_width - 1):\n",
    "            #        next_tile = next(gen)\n",
    "            #        row_tiles = np.concatenate((row_tiles, next_tile), axis=1)\n",
    "            #    returnimage.append(row_tiles)\n",
    "            #\n",
    "            #returnimage = np.array(returnimage)\n",
    "            #returnimage = np.vstack(returnimage)\n",
    "\n",
    "            for i in range(tile_width):\n",
    "                row_tiles = next(gen)\n",
    "                for j in range(tile_height - 1):\n",
    "                    next_tile = next(gen)\n",
    "                    row_tiles = np.concatenate((row_tiles, next_tile), axis=0)\n",
    "                returnimage.append(row_tiles)\n",
    "\n",
    "            returnimage = np.array(returnimage)\n",
    "            returnimage = np.hstack(returnimage)\n",
    "\n",
    "            # from array (0-1) to Image (0-255)\n",
    "            returnimage = np.uint8(returnimage * 255)\n",
    "            \n",
    "            # discarding the last dimension\n",
    "            return Image.fromarray(returnimage[:,:,0])   \n",
    "\n",
    "        \n",
    "    def denoise(self):\n",
    "        \n",
    "        self._say(\"Denoising red channel..\")\n",
    "        denoised_r = self._image_rebuilder(\n",
    "            self.image.getchannel(\"R\"), self.model, self.tile_size\n",
    "        )\n",
    "        \n",
    "        self._say(\"Denoising green channel..\")\n",
    "        denoised_g = self._image_rebuilder(\n",
    "            self.image.getchannel(\"G\"), self.model, self.tile_size\n",
    "        )\n",
    "        \n",
    "        self._say(\"Denoising blue channel..\")\n",
    "        denoised_b = self._image_rebuilder(\n",
    "            self.image.getchannel(\"B\"), self.model, self.tile_size\n",
    "        )\n",
    "        \n",
    "        rgb = Image.merge(\"RGB\",(denoised_r, denoised_g, denoised_b))\n",
    "        \n",
    "        \n",
    "        self.denoised_ = rgb\n",
    "        del denoised_r, denoised_g, denoised_b\n",
    "        self._say(\"Denoised image in 'denoised_' attribute.\")\n",
    "        \n",
    "        return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "attended-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"standard_dataset/dataset_0004_ISO1600.JPG\")\n",
    "d = Denoiser(img, model4, tile_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.denoise()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
