{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec24bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "from keras.constraints import max_norm\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123d0809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tento di scrivere una funzione che ricostruisca l'immagine.\n",
    "# step 1: multiplo esatto delle tile size\n",
    "\n",
    "# TODO: restructure code\n",
    "\n",
    "# params ===\n",
    "#tile_size=256\n",
    "#model = keras.models.load_model(\"model_dset2_56px_neuralnet_vanilla\")\n",
    "\n",
    "\n",
    "def predict_tiles_from_image(image, model, tile_size=56):\n",
    "    \"\"\" This gives back the denoised <tiles>, according to the loaded <model>\n",
    "    The model operates on multiple tiles at once. All tiles are shaped into a form\n",
    "    that the model was trained for, then all put into a np.array container.\n",
    "    This is the way the models expects the tiles for the prediction.\n",
    "    \n",
    "    NOTE: This function relies on crop_in_tiles() function.\n",
    "    \n",
    "    params\n",
    "    ======\n",
    "    \n",
    "    <image>: a pillow Image object\n",
    "    <model>: a keras trained model\n",
    "    \"\"\"\n",
    "    to_predict = [\n",
    "        x.reshape(tile_size, tile_size, 1) for x in crop_in_tiles(image, tile_size)\n",
    "    ]\n",
    "    \n",
    "    to_predict = np.array(to_predict)\n",
    "    \n",
    "    return model.predict(to_predict)\n",
    "    \n",
    "\n",
    "# from Dataset class\n",
    "def crop_in_tiles(image, tile_size=56, shift=0, asarray=True):\n",
    "\n",
    "    \"\"\"\n",
    "    This generator function crops an image in several tiles\n",
    "    tile_size × tile_size squares, yielding a tile\n",
    "    every iteration.\n",
    "\n",
    "    If the input image is not a perfect multiple of\n",
    "    a(tile_size) × b(tile_size), non-square tiles are NOT\n",
    "    YIELDED.\n",
    "\n",
    "    params\n",
    "    ======\n",
    "\n",
    "    image: a Pillow open image\n",
    "    tile_size: <int> pixels; size of the tile side\n",
    "    shift: <int>: the offset from 0,0 in pixels\n",
    "    \"\"\"\n",
    "\n",
    "    assert isinstance(tile_size, int)\n",
    "    assert isinstance(shift, int)\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    #calculate coordinates of every tile\n",
    "    for x in range (0+shift, width, tile_size):\n",
    "        if width - x < tile_size:\n",
    "            continue\n",
    "\n",
    "        for y in range (0+shift, height, tile_size):\n",
    "            if height - y < tile_size:\n",
    "                continue\n",
    "\n",
    "            # tile coord ===\n",
    "            tile_coord = (\n",
    "                x, y, # upper left coords\n",
    "                x + tile_size, y + tile_size # lower right coords\n",
    "            )\n",
    "\n",
    "            tile = image.crop(tile_coord)\n",
    "            \n",
    "            if not asarray:\n",
    "                yield tile #yielding tile as image\n",
    "            else:\n",
    "                yield np.array(tile).astype(\"float32\") / 255\n",
    "\n",
    "                \n",
    "def image_rebuilder(image, model, tile_size=56, verbose=True):\n",
    "    \"\"\" Takes an input image, splits into three channels.\n",
    "    Each channel is broken down into <tile_size> chunks, predicted and reassembled.\n",
    "    \"\"\"\n",
    "\n",
    "    def say(*args, **kwargs):\n",
    "        if verbose:\n",
    "            print(*args, **kwargs)\n",
    "    \n",
    "    # TODO: here splitting into channels\n",
    "    channels = [image] # will contain three Images, one for channel\n",
    "    \n",
    "    width, height = channels[0].size #all three channels have the same size\n",
    "    say(f\"width: {width}; height: {height}\")\n",
    "    \n",
    "    # TODO\n",
    "    # for now, we support only exact multiples of tile_size\n",
    "    tile_width = int(width / tile_size)\n",
    "    tile_height = int(height / tile_size)\n",
    "\n",
    "    say(f\"Image multiple of {tile_width}×{tile_height} integer tiles.\")\n",
    "    \n",
    "    for i, channel in enumerate(channels):\n",
    "        say(f\"Processing channel {i + 1} of {len(channels)}\")\n",
    "        \n",
    "        # TODO: tutte assieme\n",
    "        pred_tiles = [predict_tiles_from_image(channel, model, tile_size=tile_size)]\n",
    "                \n",
    "        say(f\"Predicted tiles length: {len(pred_tiles[0])}\")\n",
    "        \n",
    "        # now we need to rebuild a numpy array based on the tile_width*tile_height original geometry        \n",
    "        gen = (x for x in pred_tiles[0])\n",
    "        \n",
    "        # the final assembly is very fast ===\n",
    "        returnimage = []\n",
    "\n",
    "        #for i in range(tile_height):\n",
    "        #    row_tiles = next(gen)\n",
    "        #    for j in range(tile_width - 1):\n",
    "        #        next_tile = next(gen)\n",
    "        #        row_tiles = np.concatenate((row_tiles, next_tile), axis=1)\n",
    "        #    returnimage.append(row_tiles)\n",
    "        #\n",
    "        #returnimage = np.array(returnimage)\n",
    "        #returnimage = np.vstack(returnimage)\n",
    "        \n",
    "        for i in range(tile_width):\n",
    "            row_tiles = next(gen)\n",
    "            for j in range(tile_height - 1):\n",
    "                next_tile = next(gen)\n",
    "                row_tiles = np.concatenate((row_tiles, next_tile), axis=0)\n",
    "            returnimage.append(row_tiles)\n",
    "        \n",
    "        returnimage = np.array(returnimage)\n",
    "        returnimage = np.hstack(returnimage)\n",
    "        \n",
    "        # from array to Image\n",
    "        returnimage = np.uint8(returnimage * 256)\n",
    "        \n",
    "        # TODO: the three channels\n",
    "        return Image.fromarray(returnimage[:,:,0])        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "recorded-witch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg\r\n",
      "1.jpg\r\n",
      "\u001b[34m15_epochs\u001b[m\u001b[m\r\n",
      "2.jpg\r\n",
      "3.jpg\r\n",
      "4.jpg\r\n",
      "5.jpg\r\n",
      "Building an Image Denoiser with a Keras autoencoder neural network.pdf\r\n",
      "\u001b[31mDenoiser.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mDenoiser_with_own_dataset-LAPTOP-BD7NICPD.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mDenoiser_with_own_dataset.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mRebuilder.ipynb\u001b[m\u001b[m\r\n",
      "\u001b[31mdataset shooting info.xlsx\u001b[m\u001b[m\r\n",
      "\u001b[34mlino\u001b[m\u001b[m\r\n",
      "\u001b[34mmodel_128px_neuralnet_128_64_64_128_kernel3x3\u001b[m\u001b[m\r\n",
      "model_1_chan_B_ts_512.png\r\n",
      "model_1_chan_G_ts_512.png\r\n",
      "model_1_chan_R_ts_512.png\r\n",
      "model_2_chan_R_ts_512.png\r\n",
      "\u001b[34mmodel_56px_neuralnet_128_64_64_128_kernel3x3\u001b[m\u001b[m\r\n",
      "\u001b[34mmodel_56px_neuralnet_128_64_64_128_kernel6x6\u001b[m\u001b[m\r\n",
      "\u001b[34mmodel_56px_neuralnet_vanilla\u001b[m\u001b[m\r\n",
      "\u001b[34mmodel_ds2_56px_neuralnet_vanilla\u001b[m\u001b[m\r\n",
      "\u001b[34mmodel_dset2_56px_neuralnet_vanilla\u001b[m\u001b[m\r\n",
      "\u001b[34mstandard_dataset\u001b[m\u001b[m\r\n",
      "test 168×112px.png\r\n",
      "\u001b[34mtest_tiles\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77215c3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "# TODO: put all this within functions, classes even better\n",
    "model1 = keras.models.load_model(\"model_56px_neuralnet_128_64_64_128_kernel3x3\")\n",
    "model2 = keras.models.load_model(\"model_128px_neuralnet_128_64_64_128_kernel3x3\")\n",
    "model3 = keras.models.load_model(\"model_dset2_56px_neuralnet_vanilla\")\n",
    "\n",
    "\n",
    "img = Image.open(\"standard_dataset/dataset_0004_ISO1600.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "awful-relative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tile size: 512\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 56, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 1), dtype=tf.float32, name='conv2d_19_input'), name='conv2d_19_input', description=\"created by layer 'conv2d_19_input'\"), but it was called on an input with incompatible shape (None, 512, 512, 1).\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 128, 128, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 128, 128, 1), dtype=tf.float32, name='conv2d_31_input'), name='conv2d_31_input', description=\"created by layer 'conv2d_31_input'\"), but it was called on an input with incompatible shape (None, 512, 512, 1).\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 56, 56, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 56, 56, 1), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\"), but it was called on an input with incompatible shape (None, 512, 512, 1).\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n",
      "width: 5184; height: 3456\n",
      "Image multiple of 10×6 integer tiles.\n",
      "Processing channel 1 of 1\n",
      "Predicted tiles length: 60\n"
     ]
    }
   ],
   "source": [
    "ts = 512 # +128\n",
    "print(f\"Tile size: {ts}\")\n",
    "\n",
    "for i, model in enumerate([model1, model2, model3]):\n",
    "    for channel in \"RGB\":\n",
    "        rebuilt = image_rebuilder(img.getchannel(channel), model, tile_size=ts)\n",
    "        \n",
    "        outname = f\"model_{i+1}_chan_{channel}_ts_{str(ts)}.png\"\n",
    "        rebuilt.save(outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "royal-competition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1_chan_B_ts_512.png',\n",
       " 'model_1_chan_G_ts_512.png',\n",
       " 'model_1_chan_R_ts_512.png',\n",
       " 'model_2_chan_B_ts_512.png',\n",
       " 'model_2_chan_G_ts_512.png',\n",
       " 'model_2_chan_R_ts_512.png',\n",
       " 'model_3_chan_B_ts_512.png',\n",
       " 'model_3_chan_G_ts_512.png',\n",
       " 'model_3_chan_R_ts_512.png',\n",
       " 'test 168×112px.png']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "png = sorted(glob(\"*.png\"))\n",
    "png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "balanced-elements",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1_chan_B_ts_512.png',\n",
       " 'model_1_chan_G_ts_512.png',\n",
       " 'model_1_chan_R_ts_512.png',\n",
       " 'model_2_chan_B_ts_512.png',\n",
       " 'model_2_chan_G_ts_512.png',\n",
       " 'model_2_chan_R_ts_512.png',\n",
       " 'model_3_chan_B_ts_512.png',\n",
       " 'model_3_chan_G_ts_512.png',\n",
       " 'model_3_chan_R_ts_512.png',\n",
       " 'test 168×112px.png']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    r = Image.open(f\"model_{i+1}_chan_R_ts_512.png\")\n",
    "    g = Image.open(f\"model_{i+1}_chan_G_ts_512.png\")\n",
    "    b = Image.open(f\"model_{i+1}_chan_B_ts_512.png\")\n",
    "    r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-skiing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
